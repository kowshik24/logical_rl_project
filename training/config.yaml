model_name: "microsoft/DialoGPT-small"
learning_rate: 1e-5
total_episodes: 1000
max_steps_per_episode: 10
batch_size: 32
gamma: 0.99
epsilon: 0.2